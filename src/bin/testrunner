#!/usr/bin/env bash
set -eu -o pipefail -o errtrace
shopt -s inherit_errexit nullglob compat"${BASH_COMPAT=42}"

source "$(dirname "$(dirname "${BASH_SOURCE[0]}")")/lib/bud.rc"

TESTRUNNER_SPECIFICATION='{
    "usage": "testrunner [OPTION]... [DIRECTORY]",
    "description":[
      "Runs tests under the DIRECTORY.",
      "The reports are created under the same DIRECTORY unless the --test-reportdir option is given"
    ],
    "options":[
      ["h","help",false,false,"show this help"],
      ["p","parallel",false,false,"execute the tests in parallel"],
      ["f","filter",true,[".*"],"filter tests with the specified regular expression"],
      ["","test-reportdir",true,[],"write test reports under the specified directory"]
    ],
    "examples":{
      "testrunner DIR": "Run tests found under DIR with the testrunner in sequential mode.",
      "testrunner DIR -p": "Run tests found under DIR with the testrunner in parallel mode."
    },
    "references":{
      "github project": "https://github.com/dakusui/bud"
    }
  }'

function list_tests() {
  local _test_rootdir="${1%/}"
  find "${_test_rootdir}" -name '*.json' -or -name '*.sh' |
    grep -E '(test-.+|.*-test|test)(\.sh|\.json)' |
    sed -r 's!'"${_test_rootdir}/"'!!' |
    sort
}

function precheck_each_test() {
  local _testname="${1}" _testdir="${2}" _out="${3}"
  __execute_test_stage "${_testname}" "${_testdir}" "precheck" "precheck" "precheck" "${_out}"
}

function execute_each_test() {
  local _testname="${1}" _testdir="${2}" _errout="${3}"
  __execute_test_stage "${_testname}" "${_testdir}" "execute" "success" "execution" "${_errout}"
}

function __execute_test_stage() {
  local _testname="${1}"
  local _testdir="${2}"
  local _stage_name="${3}" # execute / precheck
  local _attr_name="${4}"  # .successful / .precheck
  local _label="${5}"      # execution / precheck
  local _errout="${6}"
  local _result_json _ret
  info_begin "__execute_test_stage: ${_stage_name}: (${_testname})"
  _result_json="$("${_stage_name}_test" "${_testname}" "${_testdir}" 2>"${_errout}")" || {
    _error "DRIVER ERROR DETECTED: '${_stage_name}_test' in $(test_driver_name)"
  }
  debug "_result_json: '${_result_json}'"
  if (__is_valid "${_result_json}" "${_attr_name}"); then
    debug "valid"
    echo "${_result_json}"
  else
    debug "not valid"
    local _err
    _err="$(cat "${_errout}")"
    jq -ncrM --arg v "${_result_json}" --arg w "${_err}" '{"report":{"result":{"'"${_label}"'":null},"driverOutput":{"stdout":$v,"stderr":$w}}}'
  fi
  info_end "__execute_test_stage: ${_stage_name}: (${_testname})"
  return 0
}

function __is_valid() {
  local _content="${1}" _attr_name="${2}"
  local _exit_code=0
  (echo "${_content}" | jq ".report.result.${_attr_name}") >&/dev/null || {
    _exit_code=1
  }
  json_object_merge "${_content}" '{}' >&/dev/null || {
    _exit_code=1
  }
  return "${_exit_code}"
}

#   _run
#   _passed
#   _skipped
#   _failed
#   _error
#   tests[@]
__run_each_test_dir="out"
__run_each_test_test_driver_name="unknown"
function run_each_test() {
  local _testname="${1}" _testdir="${2}" _testreportdir="${3}"
  local _precheck_result_file _execution_result_file
  info_begin "'${1}'"
  if [[ "${_testname}" == *.sh ]]; then
    info "Test type: 'scripttest'"
    __run_each_test_test_driver_name="${BUD_LIB}/testdrivers/scripttest.rc"
  elif [[ "${_testname}" == *.json ]]; then
    local _content _test_type
    _content=$(cat "${_testdir}/${_testname}")
    _test_type="$(echo "${_content}" | jq -crM '.type')"
    info "Test type: 'JSON:${_test_type}'"
    __run_each_test_test_driver_name="${BUD_LIB}/testdrivers/json_${_test_type}.rc"
  else
    abort "Unsupported test type: '${_testname}'"
  fi

  ####
  info_begin "Loading: '${__run_each_test_test_driver_name}'"
  # shellcheck disable=SC1090
  source "${__run_each_test_test_driver_name}"
  local _exit_code=$?
  [[ ${_exit_code} == 0 ]] || abort "Failed to load a test driver: '${__run_each_test_test_driver_name}'"
  info_end "Loaded: exit_code: '${_exit_code}'"
  __run_each_test_dir="${_testreportdir}/${_testname%.sh}-output"
  function bud__directory_for_output() {
    echo "${__run_each_test_dir}"
  }

  function test_driver_name() {
    echo "${__run_each_test_test_driver_name}"
  }
  local _dir
  _dir="$(bud__directory_for_output)"
  mkdir -p "${_dir}"
  touch "$(bud__file_for_exit_code)"
  touch "$(bud__file_for_stdout)"
  touch "$(bud__file_for_stderr)"
  touch "$(bud__file_for_script)"
  _precheck_result_file="${_dir}/precheck.txt"
  _execution_result_file="${_dir}/execution.txt"
  touch "${_precheck_result_file}"
  touch "${_execution_result_file}"
  ####

  local _test_result_json
  local _precheck_result _precheck_result_json_boolean='{}'
  _test_result_json="$(jq -ncrM --arg v "${_testname}" '{"name":$v}')"
  _precheck_result="$(precheck_each_test "${_testname}" "${_testdir}" "${_precheck_result_file}")"
  debug "_precheck_result: '${_precheck_result}'"
  _precheck_result_json_boolean="$(echo "${_precheck_result}" | jq -crM '.report.result.precheck')"
  debug "_precheck_result_json_boolean: '${_precheck_result_json_boolean}'"
  if [[ "${_precheck_result_json_boolean}" == 'true' ]]; then
    local _execution_result
    debug "trying to execute: '${_testname}'"
    _execution_result="$(execute_each_test "${_testname}" "${_testdir}" "${_execution_result_file}")"
    debug "_execution_result: '${_execution_result}'"
    _test_result_json="$(json_object_merge "${_execution_result}" "${_test_result_json}")"
  fi
  debug "_test_result_json: '${_test_result_json}'"
  _test_result_json="$(json_object_merge "${_precheck_result}" "${_test_result_json}")"
  echo "${_test_result_json}" | jq -crM .
  info_end "${1}"
}

function run_tests() {
  local _test_rootdir="${1:?Test Root Directory is missing.}"
  local _test_filter="${2:-.*}"
  local _test_reportdir="${3:-${_test_rootdir}}"
  local _parallel="${4:-true}"
  _test_rootdir="${_test_rootdir%/}"
  local -a _tests
  info_begin "_test_rootdir: '${_test_rootdir}'; _test_filter: '${_test_filter}'; _test_reportdir: '${_test_reportdir}'"
  mapfile -t _tests < <(list_tests "${_test_rootdir}" | grep -E "${_test_filter}" || abort "Failed to list tests in directory:'${_test_rootdir}' with filter: '${_test_filter}'")
  [[ "${#_tests[@]}" -gt 0 ]] || abort "No available tests.: (directory: '${_test_rootdir}', filter: '${_test_filter}')"
  local _passed=0 _skipped=0 _failed=0 _error=0 _run=0 _numtests=0 _test_results=()
  local _i _parallel_execution=""
  local -a _test_result_files=()
  ensure_no_bg_jobs
  for _i in "${_tests[@]}"; do
    _each_test_result_file="$(bud_temp_file)"
    if ${_parallel}; then
      run_each_test "${_i}" "${_test_rootdir}" "${_test_reportdir}" ${_parallel_execution} "${_parallel_execution}" >"${_each_test_result_file}" &
    else
      run_each_test "${_i}" "${_test_rootdir}" "${_test_reportdir}" ${_parallel_execution} "${_parallel_execution}" >"${_each_test_result_file}"
    fi
    _test_result_files+=("${_each_test_result_file}")
  done
  wait_for_jobs

  _numtests="${#_tests[@]}"
  for _i in "${_test_result_files[@]}"; do
    _each_test_result_content="$(cat "${_i}")"
    _test_results+=("${_each_test_result_content}")
    local _precheck _execution
    _precheck="$(echo "${_each_test_result_content}" | jq '.report.result.precheck')"
    if [[ "${_precheck}" == true ]]; then
      _run=$((_run + 1))
      _execution="$(echo "${_each_test_result_content}" | jq '.report.result.success')"
      if [[ "${_execution}" == true ]]; then
        _passed=$((_passed + 1))
      elif [[ "${_execution}" == false ]]; then
        _failed=$((_failed + 1))
      else
        _error=$((_error + 1))
      fi
    elif [[ "${_precheck}" == false ]]; then
      _skipped=$((_skipped + 1))
    else
      _error=$((_error + 1))
    fi
  done
  local _was_successful=false
  [[ "${_failed}" == 0 && "${_error}" == 0 && "${#_tests[@]}" -gt 0 ]] && _was_successful=true
  local _test_results_json
  _test_results_json="$(
    for _i in "${_test_results[@]}"; do
      echo "${_i}"
    done | jq -s .
  )"

  local _ret
  _ret="$(jq -ncrM \
    --argjson was_successful "${_was_successful}" \
    --argjson numtests "${_numtests}" \
    --argjson run "${_run}" \
    --argjson passed "${_passed}" \
    --argjson failed "${_failed}" \
    --argjson error "${_error}" \
    --argjson skipped "${_skipped}" \
    --argjson test_results "${_test_results_json}" \
    '{"wasSuccessful":$was_successful,"report":{"summary":{"all":$numtests,"run":$run,"skipped":$skipped,"passed":$passed,"failed":$failed,"error":$error},"test_results":$test_results}}')"
  echo "${_ret}"
  info_end
}

function main() {
  local _parsed_opts_json
  _parsed_opts_json="$(parseopt "${TESTRUNNER_SPECIFICATION}" "${@}")"
  debug "_parsed_opts_json: '${_parsed_opts_json}'"
  local _help
  _help="$(parseopt_boolean_value_for 'help' "${_parsed_opts_json}")"
  if [[ "${_help}" == true ]]; then
    print_usage "${TESTRUNNER_SPECIFICATION}"
    return 0
  fi
  local _is_parallel _filter _test_rootdir _test_reportdir _rest
  mapfile -t _test_rootdir < <(parseopt_rest_values "${_parsed_opts_json}")
  if [[ "${#_test_rootdir[@]}" == 0 ]]; then
    abort "Test root directory was missing."
  fi
  if [[ "${#_test_rootdir[@]}" -gt 1 ]]; then
    abort "More than one test directories are specified: '${_test_rootdir[*]}'"
  fi

  _is_parallel="$(parseopt_boolean_value_for "parallel" "${_parsed_opts_json}")"
  _filter="$(parseopt_string_value_for 'filter' "${_parsed_opts_json}")"
  _test_reportdir="$(parseopt_string_value_for 'test-reportdir' "${_parsed_opts_json}" "${_test_rootdir[0]}")"
  run_tests "${_test_rootdir[0]}" "${_filter}" "${_test_reportdir}" "${_is_parallel}" "${_rest[@]:1}"
}

main "${@}"
